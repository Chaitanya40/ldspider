#summary Intro, command line parameters, proxies, and sample code

= Introduction =

The LDSpider projects aims to provide a lightweighted web crawler for the Linked Data Web. 
The library will be optimised for a pure in-memory setup. Thus, the scalability of this library is bounded to the allocated and available memory.  

= Usage =

== Command Line ==

{{{
#>java -jar ldspider.0.1.dev.jar 
 -m <max no uris>       max no of uris per pld per round
 -t <threads>                 number of threads (default 2)
 -s <seed list>               location of the seed list
 -u <uri>                         uri of an instance
 -b <on-disk queue>   use the BDB on-disk queue with URI selection based on
 -d <depth>                   depth; number of rounds (default 2)
 -f                                     do strict breadth-first
 -n                                    do not extract links - just follow redirects.
 -y                                    stay on domains of seed uris
 -h,--help                      print help
 -l <log file name>      name of access log file
 -o <file name>            name of NQ file with output
 -r <redirects>             write redirects.nx file

}}}

Usage 
{{{
#>java -jar ldspider.0.1.dev.jar -u http://example.org/foaf.rdf
}}}

=== Proxies ===

Use java -Dhttp.proxyHost=localhost -Dhttp.proxyPort=3128 to enable proxy.
Note: standard squid does not seem to cache 303 redirects (at least not the FOAF ones).

For proxy authentication, use -Dhttp.proxyUser -Dhttp.proxyPassword

http.nonProxyHosts is not implemented

(there seems to exists a way to just use system proxy settings - http_proxy env variable under Linux but that needs to be tested http://www.rgagnon.com/javadetails/java-0085.html,
System.setProperty("java.net.useSystemProxies", "true");)

== Java Code ==
{{{
Crawler c = new Crawler(threads);



/*
* SETUP ERROR HANDLING
*/
// Print to Stdout
PrintStream ps = System.out;
// Print to file
FileOutputStream fos = new FileOutputStream(cmd.getOptionValue("r"));
Callback rcb =new CallbackNQOutputStream(fos);
rcb.startDocument();
//add printstream and file stream to error handler
ErrorHandler eh = new ErrorHandlerLogger(ps, rcb);
//connect error handler with crawler
c.setErrorHandler(eh);

/*
*SETUP CRAWL FRONTIER
*/
Frontier frontier = new RankedFrontier();
//Connect errorhandler to frontier (we use the same error handler)
frontier.setErrorHandler(eh);
frontier.setBlacklist(CrawlerConstants.BLACKLIST);
//add all seeds
List<URI> seeds = new ArrayList<URI>();
seeds.add(uri);
frontier.addAll(seeds);
				

/*
* SETUP CONTENT STREAMING/WRITING
*/
//OutputCallback	
Callback nc = new NodeCollector();
// new CallbackNQOutputStream(System.out) //for streaming 
c.setOutputCallback(nc);
//link filter
c.setLinkSelectionCallback(new LinkFilterDefault(eh));
//fetch filter
c.setFetchFilter(new FetchFilterRdfXml(eh));

//run
c.evaluate(seeds, depth);
//optional: c.evaluate(seeds, depth,maxURIs);
}}}

= Dependencies =
LDSpider has the following dependencies (included in the svn repository and the jar file)
 * *NXParser* (parsing RDF/XML) http://sw.deri.org/2006/08/nxparser/
 * *HTTPClient 4* (http connection handling) http://hc.apache.org/ (with packages httpcore, httpcore-nio and httpmime)
 * *Commons CLI* (command line interface) http://commons.apache.org/cli/
 * *Norbert* (robots.txt handler) http://www.osjava.org/norbert/