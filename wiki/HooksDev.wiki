#summary Description of hooks architecture
#sidebar TableOfContents
  * [Hooks HOWTO articles]
    * [FetchFilter Web security]
    * [LinkFilter DOM manipulation]

= Introduction =

ldspider uses Hooks to adapt the behaviour of the crawler

= Hooks =

== FetchFilter ==
A fetch filter checks if a page is allowed to be downloaded.

== LinkFilter ==
A link filter filters links from a parsed document.

== ContentHandler ==
A content handler is used to handle documents and extract RDF statements from it.

=== ContentHandlerRdfXml ===

Handles RDF/XML documents.

=== ContentHandlerNx ===

Handles N-TRIPLES and N-QUADS documents.

=== ContentHandlerAny23 ===

Uses Any23 to handle all kinds of documents. This includes RDF/XML, Turtle, Notation 3, RDFa and many Microformats. Needs a running Any23 server which can be downloaded from http://any23.org.

*Parameters:*

|| *Parameter* || *Required* || *Description* ||
||any23Endpoint||no||The Any23 endpoint to be used. If ommitted, the default Any23 endpoint of a local server will be used (http://127.0.0.1:8080).||

=== ContentHandlers ===

Combines multiple content handlers.

*Parameters:*
|| *Parameter* || *Required* || *Description* ||
||handlers||yes||The content handlers. Content handlers will be prioritized by their sequence order.||

*Example:*

Combining ContentHandlerRdfXml and ContentHandlerAny23 to handle RDF/XML document locally and other documents using the Any23 server:

{{{
ContantHandler h = new ContentHandlers(new ContentHandlerRdfXml(), new ContentHandlerAny23());
crawler.setContentHandler(h);
}}}

== Sink ==
A Sink is receives the crawled statements and processes them usually by writing them to some output.

=== SinkCallback ===

Uses an Callback from the NxParser library (http://sw.deri.org/2006/08/nxparser/) to write the statements. Among others, NxParser includes callbacks to write N-QUADS and RDF/XML.

*Parameters:*

|| *Parameter* || *Required* || *Description* ||
||callback||yes||The NxParser callback to receive the statements.||
||includeProvenance||no||If true, provenance information will be included in the output.||

*Example:*

Writing the crawled data as N-QUADS to the standard output.

{{{
Sink sink = new SinkCallback(new CallbackNQOutputStream(System.out));
crawler.setOutputCallback(sink);
}}}

=== SinkSparul ===

Writes the content to a triple store using SPARQL/Update. Optionally uses Named Graphs to represent provenance.

|| *Parameter* || *Required* || *Description* ||
||sparulEndpoint||yes||The SPARQL/Update endpoint.||
||includeProvenance||yes||If true, provenance information will be included in the output.||
||graphUri||no||The graph into which all statements are written. If not given, each dataset will be written into its own graph.||

== ErrorHandler ==
An ErrorHandler ...